{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-19T10:51:33.296756Z",
     "iopub.status.busy": "2025-11-19T10:51:33.296150Z",
     "iopub.status.idle": "2025-11-19T10:51:33.556459Z",
     "shell.execute_reply": "2025-11-19T10:51:33.555860Z",
     "shell.execute_reply.started": "2025-11-19T10:51:33.296730Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T10:51:34.004827Z",
     "iopub.status.busy": "2025-11-19T10:51:34.004207Z",
     "iopub.status.idle": "2025-11-19T10:51:38.683256Z",
     "shell.execute_reply": "2025-11-19T10:51:38.682473Z",
     "shell.execute_reply.started": "2025-11-19T10:51:34.004803Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T10:51:38.685019Z",
     "iopub.status.busy": "2025-11-19T10:51:38.684552Z",
     "iopub.status.idle": "2025-11-19T10:51:42.370324Z",
     "shell.execute_reply": "2025-11-19T10:51:42.369724Z",
     "shell.execute_reply.started": "2025-11-19T10:51:38.684991Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12b335b3ab554d19873d34b35bd61c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/234 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db3497b7e3b44403a43568d0b6d24b34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sample1.json:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "450ccbabd6c64c338e96f96a7e9d4f9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số mẫu gốc: 2986\n"
     ]
    }
   ],
   "source": [
    "# ======= 3️⃣ Load dataset =======\n",
    "dataset = load_dataset(\"twice123nd/Dataset_summarization\")\n",
    "data = dataset[\"train\"]\n",
    "\n",
    "print(\"Tổng số mẫu gốc:\", len(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T10:51:46.335875Z",
     "iopub.status.busy": "2025-11-19T10:51:46.335269Z",
     "iopub.status.idle": "2025-11-19T10:51:46.341799Z",
     "shell.execute_reply": "2025-11-19T10:51:46.340954Z",
     "shell.execute_reply.started": "2025-11-19T10:51:46.335852Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số mẫu train: 2986\n",
      "\n",
      "--- Sample 1 ---\n",
      "title: Lý giải việc nhiều vụ kiện chủ tịch tỉnh ra tòa chưa được thi hành án\n",
      "document: Bộ trưởng Tư pháp Lê Thành Long vừa có báo cáo gửi Quốc hội về việc thực hiện nghị quyết giám sát chuyên đề, chất vấn thuộc lĩnh vực tư pháp.Trong lĩnh vực theo dõi thi hành án hành chính, Bộ trưởng Tư pháp cho biết từ 1/10/2023 đến hết tháng 3/2024, tòa án các cấp đã chuyển giao cho các cơ quan thi ...\n",
      "summary: Theo Bộ Tư pháp, còn nhiều bản án, quyết định của tòa về vụ án hành chính đã có hiệu lực nhưng chưa được thi hành xong, trong đó không ít bản án người phải thi hành án là UBND, chủ tịch UBND cấp tỉnh.\n",
      "\n",
      "--- Sample 2 ---\n",
      "title: Vĩnh Phúc trình Chính phủ sáp nhập 28 đơn vị hành chính cấp xã\n",
      "document: Theo lãnh đạo Sở Nội vụ tỉnh Vĩnh Phúc, từ nay tới năm 2025 không có đơn vị hành chính cấp huyện nào ở tỉnh thuộc diện phải sắp xếp, sáp nhập.Vĩnh Phúc có 6 huyện, thành phố có đơn vị hành chính cấp xã phải sắp xếp, gồm: Tam Dương, Yên Lạc, Vĩnh Tường, Sông Lô, Bình Xuyên và thành phố Phúc Yên.Tỉnh  ...\n",
      "summary: 28 đơn vị hành chính cấp xã thuộc diện sắp xếp ở tỉnh Vĩnh Phúc đã hoàn thành việc tổ chức lấy ý kiến cử tri, với tỷ lệ đồng ý trên 91,6%. UBND tỉnh đã trình Chính phủ đề án sắp xếp.\n",
      "\n",
      "--- Sample 3 ---\n",
      "title: Đưa vụ án ở Bộ Công Thương và Tập đoàn Phúc Sơn vào báo cáo gửi Quốc hội\n",
      "document: Những nội dung này có trong báo cáo công tác ngành kiểm sát, được Viện trưởng VKSND Tối cao Lê Minh Trí ký gửi Quốc hội.Từ ngày 1/10/2023 đến 31/3/2024, Viện trưởng Lê Minh Trí cho biết đã khởi tố mới 468 vụ liên quan tội phạm tham nhũng, chức vụ (tăng 2%).Theo ông Trí, các cơ quan chức năng tiếp tụ ...\n",
      "summary: Vụ Đưa, Nhận hối lộ, Lợi dụng chức vụ quyền hạn xảy ra tại Tập đoàn Phúc Sơn hay vụ Lợi dụng chức vụ, quyền hạn khi thi hành công vụ ở Bộ Công Thương, được VKSND Tối cao đưa vào báo cáo gửi Quốc hội.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Tổng số mẫu train:\", len(data))\n",
    "\n",
    "# In 3 sample đầu tiên\n",
    "for i in range(3):\n",
    "    sample = data[i]\n",
    "    print(f\"\\n--- Sample {i+1} ---\")\n",
    "    for col_name, value in sample.items():\n",
    "        # Nếu giá trị là string dài, chỉ in 300 ký tự đầu\n",
    "        if isinstance(value, str) and len(value) > 300:\n",
    "            print(f\"{col_name}: {value[:300]} ...\")\n",
    "        else:\n",
    "            print(f\"{col_name}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T10:51:48.452490Z",
     "iopub.status.busy": "2025-11-19T10:51:48.451904Z",
     "iopub.status.idle": "2025-11-19T10:51:48.470654Z",
     "shell.execute_reply": "2025-11-19T10:51:48.469880Z",
     "shell.execute_reply.started": "2025-11-19T10:51:48.452466Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['title', 'document', 'summary'],\n",
      "        num_rows: 2388\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['title', 'document', 'summary'],\n",
      "        num_rows: 299\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['title', 'document', 'summary'],\n",
      "        num_rows: 299\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "# Tách 10% làm validation, 10% làm test\n",
    "split_val_test = data.train_test_split(test_size=0.2, seed=42)  # 20% = val+test\n",
    "val_test = split_val_test['test'].train_test_split(test_size=0.5, seed=42)  # chia đều val & test\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    'train': split_val_test['train'],\n",
    "    'validation': val_test['train'],\n",
    "    'test': val_test['test']\n",
    "})\n",
    "\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T10:51:56.721643Z",
     "iopub.status.busy": "2025-11-19T10:51:56.721363Z",
     "iopub.status.idle": "2025-11-19T10:52:34.831208Z",
     "shell.execute_reply": "2025-11-19T10:52:34.830124Z",
     "shell.execute_reply.started": "2025-11-19T10:51:56.721621Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f85d0e50de4a678b487f16abdbaec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/702 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-19 10:52:06.386710: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1763549526.571563      48 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1763549526.621135      48 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caa0cafa47d04f478559a09c51576672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/904M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6da53f858174e818d29194678eb8c39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/904M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7730589843745a991a4fa399ff94f1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbce0304c2304747926c968f8af4c2f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/820k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a5cf852ea6d4eb09274d023470a6c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bc01a47145345bdab5eea3cc2d8bda7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "193fff893d514c538c5fc68592cfee85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2388 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92791259e33a4c4c85532f7baaaba666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/299 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50362e5a1f9746468df54d771c524ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/299 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model_name = \"VietAI/vit5-base\" # hoặc \"vinai/bartpho-summarization\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "max_input_length = 1024\n",
    "max_target_length = 512\n",
    "\n",
    "def preprocess_function(batch):\n",
    "    # Kết hợp title + document làm input\n",
    "    inputs = [t + \": \" + d for t, d in zip(batch[\"title\"], batch[\"document\"])]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # Summary làm target\n",
    "    labels = tokenizer(batch[\"summary\"], max_length=max_target_length, truncation=True).input_ids\n",
    "    model_inputs[\"labels\"] = labels\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T10:52:34.833216Z",
     "iopub.status.busy": "2025-11-19T10:52:34.832934Z",
     "iopub.status.idle": "2025-11-19T10:52:34.848123Z",
     "shell.execute_reply": "2025-11-19T10:52:34.847367Z",
     "shell.execute_reply.started": "2025-11-19T10:52:34.833191Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Các key có trong tokenized sample: dict_keys(['title', 'document', 'summary', 'input_ids', 'attention_mask', 'labels'])\n",
      "\n",
      "Input_ids (đầu 20 tokens): [122, 1353, 1269, 954, 1281, 3500, 382, 1541, 3395, 1245, 35862, 8375, 1855, 897, 745, 1320, 3958, 189, 35836, 35849]\n",
      "Attention_mask (đầu 20 tokens): [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Labels (đầu 20 tokens): [1399, 93, 35790, 1056, 210, 1670, 424, 900, 400, 71, 1071, 68, 235, 498, 382, 890, 35790, 871, 6898, 123]\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra tokenized sample đầu tiên\n",
    "sample = tokenized_dataset[\"train\"][0]\n",
    "\n",
    "print(\"Các key có trong tokenized sample:\", sample.keys())\n",
    "\n",
    "# In vài token đầu để kiểm tra\n",
    "print(\"\\nInput_ids (đầu 20 tokens):\", sample[\"input_ids\"][:20])\n",
    "print(\"Attention_mask (đầu 20 tokens):\", sample[\"attention_mask\"][:20])\n",
    "print(\"Labels (đầu 20 tokens):\", sample[\"labels\"][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T10:38:22.161487Z",
     "iopub.status.busy": "2025-11-18T10:38:22.161151Z",
     "iopub.status.idle": "2025-11-18T10:38:22.197708Z",
     "shell.execute_reply": "2025-11-18T10:38:22.197053Z",
     "shell.execute_reply.started": "2025-11-18T10:38:22.161465Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Input Text ==\n",
      "3 câu chuyện truyền cảm hứng chiến thắng ung thư: Cơn bạo bệnh bất ngờ ập đếnCứ nhắc tới hai chữ \"ung thư\" là người ta nghĩ ngay đến \"án tử\". Bệnh ung thư quái ác dường như đến với con người ta như một cơn bão, không được dự báo trước nên đã khiến nhiều người rơi vào tình cảnh tuyệt vọng và mất niềm tin vào cuộc sống.VTV2 HTCB số 23 - Hành trình tìm lại sự sống của bệnh nhân ung thư Vòm họngCũng giống như bao người đang mang trong mình căn bệnh hiểm nghèo này, kể về thời điểm bắt đầu phát hiện bệnh từ những cơn đau đầu không rõ nguyên nhân, Ông Trần Văn Tiến (Hà Nam) đi khám và uống thuốc Đông y 6 tháng mà không đỡ. Cho đến tận năm 2018, khi các cơn đau ngày càng nặng hơn, ông quyết định đến Bệnh viện Bạch Mai khám, ở đó bác sĩ thông báo ông bị Ung thư vòm họng giai đoạn 3.Chân dung 3 nhân vật truyền cảm hứng chiến thắng ung thư.Cơn bão ung thư cũng xảy đến với ông Vũ Huy Chương (xã Kim Hải, huyện Kim Sơn, Ninh Bình) vào năm 2002, khi cảm thấy sức khỏe yếu đi rõ rệt, đi khám được bác sĩ chẩn đoán bị viêm xương. Cho đến năm 2012, ông bị đau dữ dội ở vùng đầu và xương, sau khi thăm khám, nhận được kết quả mình bị ung thư tuyến yên khối u đã di căn vào xương.Sóng gió cũng ập đến với chị Nguyễn Thị Soi (Âu Cơ, Phường 10, Quận Tân Bình, TPHCM) vào tháng 9/2018. Chị thấy đau bụng dữ dội, cấp cứu trong tình trạng hôn mê, các cơn đau kéo dài khiến chị lịm đi. Khối u to, dài 15cm được giải phẫu với kết quả là ung thư buồng trứng phải.Người phụ nữ vực dậy sau 2 lần đại phẫu ung thưĐối mặt với án tửSau đó 1 tuần, ông Tiến lên Bệnh viện K3 Tân Triều nhập viện và được tiếp nhận điều trị theo phác đồ bao gồm cả hóa trị và xạ trị. Ông kiên trì tuân thủ theo phác đồ điều trị của bác sĩ, sáng truyền hóa chất trên tầng 7, tối lại đi xạ trị. Liệu pháp hóa xạ trị có tác dụng phụ đã vắt kiệt sức lực của ông già hơn 60 tuổi như ông. Vừa đau đớn, vừa mệt mỏi và buồn nôn, ông Tiến gần như không ăn uống gì được, cân nặng lúc đầu 55kg chỉ còn 41kg, không khác gì một bộ da bọc xương.Ông Chương kể giây phút đáng nhớ về hành trình chiến thắng ung thư của mình.Cùng suy nghĩ với ông Tiến, ông Chương tâm sự: \"Dù biết bệnh tật không chừa một ai, lúc phát hiện bệnh tôi thấy buồn lắm. Nhưng nghĩ lại thì thấy giờ này mình ra đi cũng không còn gì hối tiếc, con cháu đã có đủ cả, mình phải cố gắng để người thân không phiền lòng\". Tuổi đã cao nên ông Chương không chọn phẫu thuật bởi khối u nằm ở não, chỉ một sơ suất nhỏ có thể gây liệt toàn thân. Ông được các bác sĩ tư vấn xạ trị để hạn chế tế bào ung thư. Ông đã trải qua 15 mũi xạ trị. Lúc này, ông nghĩ cái chết có thể đến bất kỳ lúc nào nên rời viện về nhà, không còn cách nào khác, người thân chuẩn bị nhiều thuốc giảm đau liều cao để tiêm mỗi khi ông đau đớn đến mức không chịu được.Về phần chị Soi, bác sĩ giải thích với chị rằng sau phẫu thuật chị sẽ vẫn phải hóa, xạ trị để tìm diệt tế bào ung thư còn sót lại. Từ đó, chị tự nhủ mình phải chuẩn bị sức khỏe thật tốt để đối mặt với các tác dụng phụ của hóa chất và tia xạ.Ông Tiến sử dụng sản phẩm GHV Ksol mỗi ngày để duy trì sức khỏe.Hành trình chiến thắng căn bệnh ung thưSau quá trình điều trị từ bệnh viện trở về nhà, một lần tình cờ ông Tiến và ông Chương xem được chương trình truyền hình đưa tin về Viện Hàn lâm Khoa học và Công nghệ Việt Nam chế tạo thành công thực phẩm bảo vệ sức khỏe GHV KSol dành cho bệnh nhân ung thư.Ông Tiến chia sẻ: \"Không dám nghĩ là tôi có thể nói chuyện được và hát được như bây giờ. Từ khi sức khỏe cải thiện, ngày nào tôi cũng luyện tập phát âm, mỗi lần như vậy đau đớn lắm. Nhưng tôi vẫn kiên trì, luyện tập từng tí một, cuối cùng mọi công sức cũng đã được đền đáp. Tất cả là nhờ niềm tin vào khoa học, tin tưởng vào bác sĩ và sử dụng thêm sản phẩm GHV KSol đều đặn 15 viên 1 ngày, kết hợp với ăn uống và tập luyện thể dục thường xuyên\".Ý kiến đánh giá của PGS. TS Trần Đáng về sản\n",
      "\n",
      "== Summary ==\n",
      "Ba người, ba số phận khác nhau nhưng có chung một hành trình chiến đấu, chống chọi với bệnh tật và giành chiến thắng trước căn bệnh ung thư quái ác.\n",
      "\n",
      "== Attention Mask (độ dài): 1024\n",
      "== Input IDs (đầu 20): [122, 1353, 1269, 954, 1281, 3500, 382, 1541, 3395, 1245, 35862, 8375, 1855, 897, 745, 1320, 3958, 189, 35836, 35849]\n"
     ]
    }
   ],
   "source": [
    "print(\"== Input Text ==\")\n",
    "print(tokenizer.decode(sample[\"input_ids\"], skip_special_tokens=True))\n",
    "\n",
    "print(\"\\n== Summary ==\")\n",
    "print(tokenizer.decode(sample[\"labels\"], skip_special_tokens=True))\n",
    "\n",
    "print(\"\\n== Attention Mask (độ dài):\", len(sample[\"attention_mask\"]))\n",
    "print(\"== Input IDs (đầu 20):\", sample[\"input_ids\"][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T10:52:34.849123Z",
     "iopub.status.busy": "2025-11-19T10:52:34.848815Z",
     "iopub.status.idle": "2025-11-19T10:52:36.518445Z",
     "shell.execute_reply": "2025-11-19T10:52:36.517456Z",
     "shell.execute_reply.started": "2025-11-19T10:52:34.849076Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,  # rất quan trọng với T5/BART để xử lý label padding đúng\n",
    "    return_tensors=\"pt\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T10:52:36.520339Z",
     "iopub.status.busy": "2025-11-19T10:52:36.519976Z",
     "iopub.status.idle": "2025-11-19T10:52:37.392567Z",
     "shell.execute_reply": "2025-11-19T10:52:37.391730Z",
     "shell.execute_reply.started": "2025-11-19T10:52:36.520307Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./output_loss_only\",\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-5,\n",
    "\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,                  \n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=50,               \n",
    "\n",
    "    save_strategy=\"no\",              \n",
    "    predict_with_generate=True,    \n",
    "    report_to=\"none\",                \n",
    "    fp16=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T10:52:37.393638Z",
     "iopub.status.busy": "2025-11-19T10:52:37.393427Z",
     "iopub.status.idle": "2025-11-19T10:52:40.611413Z",
     "shell.execute_reply": "2025-11-19T10:52:40.610576Z",
     "shell.execute_reply.started": "2025-11-19T10:52:37.393622Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48/2783352374.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,               # vẫn giữ để dùng decode, compute_metrics\n",
    "    data_collator=data_collator       # ✅ THAY VÌ dùng tokenizer nội bộ\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T10:52:40.612438Z",
     "iopub.status.busy": "2025-11-19T10:52:40.612158Z",
     "iopub.status.idle": "2025-11-19T11:21:17.981626Z",
     "shell.execute_reply": "2025-11-19T11:21:17.980708Z",
     "shell.execute_reply.started": "2025-11-19T10:52:40.612414Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='450' max='450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [450/450 28:31, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.957400</td>\n",
       "      <td>1.741829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.717300</td>\n",
       "      <td>1.702770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.684100</td>\n",
       "      <td>1.683081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.567700</td>\n",
       "      <td>1.682881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=450, training_loss=1.7933304002549912, metrics={'train_runtime': 1716.9425, 'train_samples_per_second': 4.173, 'train_steps_per_second': 0.262, 'total_flos': 8516090557624320.0, 'train_loss': 1.7933304002549912, 'epoch': 3.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T11:21:17.982906Z",
     "iopub.status.busy": "2025-11-19T11:21:17.982545Z",
     "iopub.status.idle": "2025-11-19T11:21:19.668786Z",
     "shell.execute_reply": "2025-11-19T11:21:19.667999Z",
     "shell.execute_reply.started": "2025-11-19T11:21:17.982878Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./output_loss_only/tokenizer_config.json',\n",
       " './output_loss_only/special_tokens_map.json',\n",
       " './output_loss_only/spiece.model',\n",
       " './output_loss_only/added_tokens.json',\n",
       " './output_loss_only/tokenizer.json')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"./output_loss_only\")           # lưu model weights\n",
    "tokenizer.save_pretrained(\"./output_loss_only\")    # lưu tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T13:19:08.271284Z",
     "iopub.status.busy": "2025-11-19T13:19:08.270752Z",
     "iopub.status.idle": "2025-11-19T13:19:17.733791Z",
     "shell.execute_reply": "2025-11-19T13:19:17.732724Z",
     "shell.execute_reply.started": "2025-11-19T13:19:08.271253Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.4.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.18)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.36.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.20.0)\n",
      "Collecting pyarrow>=21.0.0 (from datasets>=2.0.0->evaluate)\n",
      "  Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (0.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.3.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.3.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.10.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.0.0->evaluate) (0.16.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2025.3.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.3.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1.0.0->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (47.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyarrow, evaluate\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 19.0.1\n",
      "    Uninstalling pyarrow-19.0.1:\n",
      "      Successfully uninstalled pyarrow-19.0.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "pylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
      "cudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
      "cudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed evaluate-0.4.6 pyarrow-22.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T13:18:00.097350Z",
     "iopub.status.busy": "2025-11-19T13:18:00.096617Z",
     "iopub.status.idle": "2025-11-19T13:19:08.269047Z",
     "shell.execute_reply": "2025-11-19T13:19:08.268060Z",
     "shell.execute_reply.started": "2025-11-19T13:18:00.097324Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert_score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.6.0+cu124)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.2.3)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from bert_score) (4.53.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bert_score) (1.26.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.11/dist-packages (from bert_score) (4.67.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert_score) (3.7.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bert_score) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2025.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->bert_score) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->bert_score) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->bert_score) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->bert_score) (2025.3.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->bert_score) (2022.3.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->bert_score) (2.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (4.15.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (2025.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.0.0->bert_score)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.0.0->bert_score)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.0.0->bert_score)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.0.0->bert_score)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.0.0->bert_score)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.0.0->bert_score)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.0.0->bert_score)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.0.0->bert_score)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.0.0->bert_score)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.0.0->bert_score)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert_score) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.36.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.5.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (1.4.8)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (11.3.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (3.0.9)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (2025.10.5)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=3.0.0->bert_score) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->bert_score) (3.0.3)\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->bert_score) (2025.3.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->bert_score) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->bert_score) (2022.3.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->bert_score) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->bert_score) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->bert_score) (2024.2.0)\n",
      "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bert_score\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed bert_score-0.3.13 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
     ]
    }
   ],
   "source": [
    "!pip install bert_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T12:32:06.601063Z",
     "iopub.status.busy": "2025-11-18T12:32:06.600778Z",
     "iopub.status.idle": "2025-11-18T12:32:06.607159Z",
     "shell.execute_reply": "2025-11-18T12:32:06.606327Z",
     "shell.execute_reply.started": "2025-11-18T12:32:06.601041Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample  1 | Precision: 0.652 | Recall: 0.686 | F1: 0.669\n",
      "Sample  2 | Precision: 0.638 | Recall: 0.743 | F1: 0.687\n",
      "Sample  3 | Precision: 0.707 | Recall: 0.791 | F1: 0.747\n",
      "Sample  4 | Precision: 0.696 | Recall: 0.742 | F1: 0.718\n",
      "Sample  5 | Precision: 0.679 | Recall: 0.747 | F1: 0.712\n",
      "Sample  6 | Precision: 0.678 | Recall: 0.730 | F1: 0.703\n",
      "Sample  7 | Precision: 0.683 | Recall: 0.782 | F1: 0.729\n",
      "Sample  8 | Precision: 0.655 | Recall: 0.720 | F1: 0.686\n",
      "Sample  9 | Precision: 0.712 | Recall: 0.756 | F1: 0.733\n",
      "Sample 10 | Precision: 0.720 | Recall: 0.785 | F1: 0.751\n",
      "Sample 11 | Precision: 0.636 | Recall: 0.678 | F1: 0.656\n",
      "Sample 12 | Precision: 0.647 | Recall: 0.711 | F1: 0.677\n",
      "Sample 13 | Precision: 0.694 | Recall: 0.708 | F1: 0.701\n",
      "Sample 14 | Precision: 0.667 | Recall: 0.731 | F1: 0.697\n",
      "Sample 15 | Precision: 0.653 | Recall: 0.725 | F1: 0.687\n",
      "Sample 16 | Precision: 0.666 | Recall: 0.743 | F1: 0.702\n",
      "Sample 17 | Precision: 0.708 | Recall: 0.741 | F1: 0.724\n",
      "Sample 18 | Precision: 0.679 | Recall: 0.733 | F1: 0.705\n",
      "Sample 19 | Precision: 0.667 | Recall: 0.739 | F1: 0.701\n",
      "Sample 20 | Precision: 0.654 | Recall: 0.697 | F1: 0.675\n",
      "Sample 21 | Precision: 0.631 | Recall: 0.689 | F1: 0.658\n",
      "Sample 22 | Precision: 0.754 | Recall: 0.823 | F1: 0.787\n",
      "Sample 23 | Precision: 0.658 | Recall: 0.726 | F1: 0.690\n",
      "Sample 24 | Precision: 0.684 | Recall: 0.768 | F1: 0.724\n",
      "Sample 25 | Precision: 0.702 | Recall: 0.737 | F1: 0.719\n",
      "Sample 26 | Precision: 0.655 | Recall: 0.714 | F1: 0.683\n",
      "Sample 27 | Precision: 0.684 | Recall: 0.742 | F1: 0.712\n",
      "Sample 28 | Precision: 0.714 | Recall: 0.758 | F1: 0.736\n",
      "Sample 29 | Precision: 0.680 | Recall: 0.795 | F1: 0.733\n",
      "Sample 30 | Precision: 0.617 | Recall: 0.712 | F1: 0.661\n",
      "Sample 31 | Precision: 0.647 | Recall: 0.711 | F1: 0.678\n",
      "Sample 32 | Precision: 0.706 | Recall: 0.766 | F1: 0.735\n",
      "Sample 33 | Precision: 0.663 | Recall: 0.738 | F1: 0.698\n",
      "Sample 34 | Precision: 0.683 | Recall: 0.769 | F1: 0.723\n",
      "Sample 35 | Precision: 0.734 | Recall: 0.779 | F1: 0.756\n",
      "Sample 36 | Precision: 0.658 | Recall: 0.745 | F1: 0.699\n",
      "Sample 37 | Precision: 0.671 | Recall: 0.785 | F1: 0.723\n",
      "Sample 38 | Precision: 0.701 | Recall: 0.755 | F1: 0.727\n",
      "Sample 39 | Precision: 0.679 | Recall: 0.808 | F1: 0.738\n",
      "Sample 40 | Precision: 0.702 | Recall: 0.757 | F1: 0.729\n",
      "Sample 41 | Precision: 0.662 | Recall: 0.706 | F1: 0.683\n",
      "Sample 42 | Precision: 0.666 | Recall: 0.743 | F1: 0.702\n",
      "Sample 43 | Precision: 0.723 | Recall: 0.803 | F1: 0.760\n",
      "Sample 44 | Precision: 0.680 | Recall: 0.742 | F1: 0.709\n",
      "Sample 45 | Precision: 0.703 | Recall: 0.771 | F1: 0.735\n",
      "Sample 46 | Precision: 0.730 | Recall: 0.793 | F1: 0.761\n",
      "Sample 47 | Precision: 0.660 | Recall: 0.703 | F1: 0.681\n",
      "Sample 48 | Precision: 0.728 | Recall: 0.799 | F1: 0.762\n",
      "Sample 49 | Precision: 0.698 | Recall: 0.787 | F1: 0.739\n",
      "Sample 50 | Precision: 0.684 | Recall: 0.763 | F1: 0.721\n",
      "\n",
      "Average | Precision: 0.681 | Recall: 0.748 | F1: 0.713\n"
     ]
    }
   ],
   "source": [
    "for i, (p, r, f) in enumerate(zip(results['precision'], results['recall'], results['f1']), 1):\n",
    "    print(f\"Sample {i:2d} | Precision: {p:.3f} | Recall: {r:.3f} | F1: {f:.3f}\")\n",
    "# Tính trung bình\n",
    "avg_precision = sum(results['precision']) / len(results['precision'])\n",
    "avg_recall = sum(results['recall']) / len(results['recall'])\n",
    "avg_f1 = sum(results['f1']) / len(results['f1'])\n",
    "\n",
    "print(\"\\nAverage | Precision: {:.3f} | Recall: {:.3f} | F1: {:.3f}\".format(\n",
    "    avg_precision, avg_recall, avg_f1\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T11:21:40.798400Z",
     "iopub.status.busy": "2025-11-19T11:21:40.798100Z",
     "iopub.status.idle": "2025-11-19T11:21:42.121963Z",
     "shell.execute_reply": "2025-11-19T11:21:42.121395Z",
     "shell.execute_reply.started": "2025-11-19T11:21:40.798379Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T11:21:49.854384Z",
     "iopub.status.busy": "2025-11-19T11:21:49.853831Z",
     "iopub.status.idle": "2025-11-19T11:21:55.283606Z",
     "shell.execute_reply": "2025-11-19T11:21:55.282607Z",
     "shell.execute_reply.started": "2025-11-19T11:21:49.854358Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (2.7.1)\n",
      "Collecting openai\n",
      "  Downloading openai-2.8.1-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.12.4)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Downloading openai-2.8.1-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 2.7.1\n",
      "    Uninstalling openai-2.7.1:\n",
      "      Successfully uninstalled openai-2.7.1\n",
      "Successfully installed openai-2.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T11:22:00.451836Z",
     "iopub.status.busy": "2025-11-19T11:22:00.451287Z",
     "iopub.status.idle": "2025-11-19T11:22:00.706739Z",
     "shell.execute_reply": "2025-11-19T11:22:00.705972Z",
     "shell.execute_reply.started": "2025-11-19T11:22:00.451805Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T12:37:59.183950Z",
     "iopub.status.busy": "2025-11-18T12:37:59.183726Z",
     "iopub.status.idle": "2025-11-18T12:37:59.187331Z",
     "shell.execute_reply": "2025-11-18T12:37:59.186788Z",
     "shell.execute_reply.started": "2025-11-18T12:37:59.183933Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T12:38:05.393522Z",
     "iopub.status.busy": "2025-11-18T12:38:05.392617Z",
     "iopub.status.idle": "2025-11-18T12:38:05.400727Z",
     "shell.execute_reply": "2025-11-18T12:38:05.399773Z",
     "shell.execute_reply.started": "2025-11-18T12:38:05.393495Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ===== Hàm đánh giá summarization với GPT-4o-mini =====\n",
    "def evaluate_summarization_gpt4o_vi(document, reference, prediction):\n",
    "    system_prompt = \"\"\"\n",
    "Bạn là chuyên gia đánh giá tóm tắt văn bản.\n",
    "Đánh giá 4 tiêu chí (1–10):\n",
    "1️⃣ Fluency: Lưu loát & mạch lạc.\n",
    "2️⃣ Relevance: Liên quan & Hữu ích.\n",
    "3️⃣ Faithfulness: Độ trung thực với nội dung gốc.\n",
    "4️⃣ Conciseness: Ngắn gọn, súc tích.\n",
    "\n",
    "Phải phản hồi **JSON hợp lệ**:\n",
    "{\n",
    "  \"fluency\": <điểm>,\n",
    "  \"relevance\": <điểm>,\n",
    "  \"faithfulness\": <điểm>,\n",
    "  \"conciseness\": <điểm>,\n",
    "  \"average\": <điểm>\n",
    "}\n",
    "\"\"\"\n",
    "    evaluation_prompt = f\"\"\"\n",
    "Văn bản gốc:\n",
    "{document}\n",
    "\n",
    "Tóm tắt chuẩn (reference):\n",
    "{reference}\n",
    "\n",
    "Tóm tắt mô hình (prediction):\n",
    "{prediction}\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": evaluation_prompt}\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        raw_text = response.choices[0].message.content.strip()\n",
    "        result = json.loads(raw_text)\n",
    "    except Exception as e:\n",
    "        print(\"⚠️ Lỗi API hoặc lỗi JSON:\", e)\n",
    "        result = {k: None for k in [\"fluency\",\"relevance\",\"faithfulness\",\"conciseness\",\"average\"]}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T12:38:05.760434Z",
     "iopub.status.busy": "2025-11-18T12:38:05.759951Z",
     "iopub.status.idle": "2025-11-18T12:39:19.146167Z",
     "shell.execute_reply": "2025-11-18T12:39:19.145523Z",
     "shell.execute_reply.started": "2025-11-18T12:38:05.760413Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:13<00:00,  1.47s/it]\n"
     ]
    }
   ],
   "source": [
    "# ===== Đánh giá tập 50 tóm tắt =====\n",
    "scores = {\"fluency\": [], \"relevance\": [], \"faithfulness\": [], \"conciseness\": [], \"average\": []}\n",
    "\n",
    "for doc, ref, pred in tqdm(zip(test_dataset[\"document\"][:50],\n",
    "                               test_dataset[\"summary\"][:50],\n",
    "                               pred_summaries), total=50):\n",
    "    res = evaluate_summarization_gpt4o_vi(doc, ref, pred)\n",
    "    for key in scores:\n",
    "        scores[key].append(res[key])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T12:39:19.147642Z",
     "iopub.status.busy": "2025-11-18T12:39:19.147338Z",
     "iopub.status.idle": "2025-11-18T12:39:19.158499Z",
     "shell.execute_reply": "2025-11-18T12:39:19.157727Z",
     "shell.execute_reply.started": "2025-11-18T12:39:19.147615Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample  1 | Fluency: 6.00 | Relevance: 7.00 | Faithfulness: 5.00 | Conciseness: 4.00 | Avg: 5.50\n",
      "Sample  2 | Fluency: 6.00 | Relevance: 7.00 | Faithfulness: 5.00 | Conciseness: 4.00 | Avg: 5.50\n",
      "Sample  3 | Fluency: 7.00 | Relevance: 9.00 | Faithfulness: 8.00 | Conciseness: 6.00 | Avg: 7.50\n",
      "Sample  4 | Fluency: 6.00 | Relevance: 7.00 | Faithfulness: 5.00 | Conciseness: 6.00 | Avg: 6.00\n",
      "Sample  5 | Fluency: 5.00 | Relevance: 6.00 | Faithfulness: 4.00 | Conciseness: 3.00 | Avg: 4.50\n",
      "Sample  6 | Fluency: 8.00 | Relevance: 9.00 | Faithfulness: 7.00 | Conciseness: 6.00 | Avg: 7.50\n",
      "Sample  7 | Fluency: 7.00 | Relevance: 6.00 | Faithfulness: 5.00 | Conciseness: 6.00 | Avg: 6.00\n",
      "Sample  8 | Fluency: 7.00 | Relevance: 9.00 | Faithfulness: 8.00 | Conciseness: 6.00 | Avg: 7.50\n",
      "Sample  9 | Fluency: 8.00 | Relevance: 9.00 | Faithfulness: 7.00 | Conciseness: 6.00 | Avg: 7.50\n",
      "Sample 10 | Fluency: 8.00 | Relevance: 9.00 | Faithfulness: 7.00 | Conciseness: 6.00 | Avg: 7.50\n",
      "Sample 11 | Fluency: 8.00 | Relevance: 9.00 | Faithfulness: 7.00 | Conciseness: 6.00 | Avg: 7.50\n",
      "Sample 12 | Fluency: 7.00 | Relevance: 8.00 | Faithfulness: 6.00 | Conciseness: 7.00 | Avg: 7.00\n",
      "Sample 13 | Fluency: 6.00 | Relevance: 7.00 | Faithfulness: 5.00 | Conciseness: 4.00 | Avg: 5.50\n",
      "Sample 14 | Fluency: 5.00 | Relevance: 7.00 | Faithfulness: 4.00 | Conciseness: 6.00 | Avg: 5.50\n",
      "Sample 15 | Fluency: 7.00 | Relevance: 6.00 | Faithfulness: 5.00 | Conciseness: 4.00 | Avg: 5.50\n",
      "Sample 16 | Fluency: 6.00 | Relevance: 7.00 | Faithfulness: 5.00 | Conciseness: 4.00 | Avg: 5.50\n",
      "Sample 17 | Fluency: 8.00 | Relevance: 7.00 | Faithfulness: 6.00 | Conciseness: 5.00 | Avg: 6.50\n",
      "Sample 18 | Fluency: 8.00 | Relevance: 9.00 | Faithfulness: 8.00 | Conciseness: 7.00 | Avg: 8.00\n",
      "Sample 19 | Fluency: 6.00 | Relevance: 7.00 | Faithfulness: 5.00 | Conciseness: 6.00 | Avg: 6.00\n",
      "Sample 20 | Fluency: 3.00 | Relevance: 4.00 | Faithfulness: 2.00 | Conciseness: 3.00 | Avg: 3.00\n",
      "Sample 21 | Fluency: 7.00 | Relevance: 8.00 | Faithfulness: 6.00 | Conciseness: 5.00 | Avg: 6.50\n",
      "Sample 22 | Fluency: 5.00 | Relevance: 6.00 | Faithfulness: 4.00 | Conciseness: 3.00 | Avg: 4.50\n",
      "Sample 23 | Fluency: 6.00 | Relevance: 8.00 | Faithfulness: 5.00 | Conciseness: 4.00 | Avg: 5.75\n",
      "Sample 24 | Fluency: 6.00 | Relevance: 5.00 | Faithfulness: 4.00 | Conciseness: 5.00 | Avg: 5.00\n",
      "Sample 25 | Fluency: 8.00 | Relevance: 9.00 | Faithfulness: 7.00 | Conciseness: 6.00 | Avg: 7.50\n",
      "Sample 26 | Fluency: 7.00 | Relevance: 8.00 | Faithfulness: 6.00 | Conciseness: 5.00 | Avg: 6.50\n",
      "Sample 27 | Fluency: 4.00 | Relevance: 6.00 | Faithfulness: 5.00 | Conciseness: 3.00 | Avg: 4.50\n",
      "Sample 28 | Fluency: 4.00 | Relevance: 5.00 | Faithfulness: 4.00 | Conciseness: 3.00 | Avg: 4.00\n",
      "Sample 29 | Fluency: 8.00 | Relevance: 9.00 | Faithfulness: 8.00 | Conciseness: 7.00 | Avg: 8.00\n",
      "Sample 30 | Fluency: 6.00 | Relevance: 8.00 | Faithfulness: 7.00 | Conciseness: 5.00 | Avg: 6.50\n",
      "Sample 31 | Fluency: 8.00 | Relevance: 7.00 | Faithfulness: 6.00 | Conciseness: 5.00 | Avg: 6.50\n",
      "Sample 32 | Fluency: 8.00 | Relevance: 9.00 | Faithfulness: 7.00 | Conciseness: 6.00 | Avg: 7.50\n",
      "Sample 33 | Fluency: 5.00 | Relevance: 6.00 | Faithfulness: 4.00 | Conciseness: 5.00 | Avg: 5.00\n",
      "Sample 34 | Fluency: 7.00 | Relevance: 8.00 | Faithfulness: 6.00 | Conciseness: 5.00 | Avg: 6.50\n",
      "Sample 35 | Fluency: 7.00 | Relevance: 8.00 | Faithfulness: 7.00 | Conciseness: 6.00 | Avg: 7.00\n",
      "Sample 36 | Fluency: 8.00 | Relevance: 9.00 | Faithfulness: 7.00 | Conciseness: 6.00 | Avg: 7.50\n",
      "Sample 37 | Fluency: 6.00 | Relevance: 7.00 | Faithfulness: 5.00 | Conciseness: 4.00 | Avg: 5.50\n",
      "Sample 38 | Fluency: 7.00 | Relevance: 8.00 | Faithfulness: 6.00 | Conciseness: 7.00 | Avg: 7.00\n",
      "Sample 39 | Fluency: 5.00 | Relevance: 4.00 | Faithfulness: 3.00 | Conciseness: 4.00 | Avg: 4.00\n",
      "Sample 40 | Fluency: 8.00 | Relevance: 9.00 | Faithfulness: 8.00 | Conciseness: 7.00 | Avg: 8.00\n",
      "Sample 41 | Fluency: 5.00 | Relevance: 6.00 | Faithfulness: 5.00 | Conciseness: 4.00 | Avg: 5.00\n",
      "Sample 42 | Fluency: 6.00 | Relevance: 8.00 | Faithfulness: 7.00 | Conciseness: 5.00 | Avg: 6.50\n",
      "Sample 43 | Fluency: 8.00 | Relevance: 9.00 | Faithfulness: 7.00 | Conciseness: 6.00 | Avg: 7.50\n",
      "Sample 44 | Fluency: 8.00 | Relevance: 7.00 | Faithfulness: 6.00 | Conciseness: 5.00 | Avg: 6.50\n",
      "Sample 45 | Fluency: 6.00 | Relevance: 5.00 | Faithfulness: 4.00 | Conciseness: 5.00 | Avg: 5.00\n",
      "Sample 46 | Fluency: 8.00 | Relevance: 7.00 | Faithfulness: 6.00 | Conciseness: 5.00 | Avg: 6.50\n",
      "Sample 47 | Fluency: 8.00 | Relevance: 9.00 | Faithfulness: 7.00 | Conciseness: 6.00 | Avg: 7.50\n",
      "Sample 48 | Fluency: 6.00 | Relevance: 7.00 | Faithfulness: 5.00 | Conciseness: 4.00 | Avg: 5.50\n",
      "Sample 49 | Fluency: 7.00 | Relevance: 8.00 | Faithfulness: 7.00 | Conciseness: 6.00 | Avg: 7.00\n",
      "Sample 50 | Fluency: 8.00 | Relevance: 9.00 | Faithfulness: 7.00 | Conciseness: 6.00 | Avg: 7.50\n",
      "\n",
      "Average | Fluency: 6.64 | Relevance: 7.42 | Faithfulness: 5.80 | Conciseness: 5.16 | Avg: 6.25\n"
     ]
    }
   ],
   "source": [
    "# ===== Chuyển sang DataFrame =====\n",
    "df_scores = pd.DataFrame(scores)\n",
    "# ===== Tính trung bình toàn bộ =====\n",
    "avg_scores = df_scores.mean()\n",
    "print(\"\\nAverage | Fluency: {:.2f} | Relevance: {:.2f} | Faithfulness: {:.2f} | Conciseness: {:.2f} | Avg: {:.2f}\"\n",
    "      .format(avg_scores['fluency'], avg_scores['relevance'], avg_scores['faithfulness'],\n",
    "              avg_scores['conciseness'], avg_scores['average']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T11:27:56.107797Z",
     "iopub.status.busy": "2025-11-19T11:27:56.107500Z",
     "iopub.status.idle": "2025-11-19T11:27:56.112705Z",
     "shell.execute_reply": "2025-11-19T11:27:56.111884Z",
     "shell.execute_reply.started": "2025-11-19T11:27:56.107775Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_synthetic_summary(title, document):\n",
    "    prompt = f\"\"\"\n",
    "Bạn là mô hình tóm tắt tiếng Việt.\n",
    "Hãy viết bản tóm tắt ngắn, rõ ràng, không bỏ ý.\n",
    "\n",
    "Tiêu đề: {title}\n",
    "\n",
    "Văn bản:\n",
    "{document}\n",
    "\n",
    "Yêu cầu: Tóm tắt 3–5 câu, không thêm thông tin mới.\n",
    "\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Bạn là mô hình tóm tắt tiếng Việt.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.3\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T11:27:57.887332Z",
     "iopub.status.busy": "2025-11-19T11:27:57.886606Z",
     "iopub.status.idle": "2025-11-19T11:55:51.715038Z",
     "shell.execute_reply": "2025-11-19T11:55:51.714147Z",
     "shell.execute_reply.started": "2025-11-19T11:27:57.887298Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0   3 câu chuyện truyền cảm hứng chiến thắng ung thư   \n",
      "1        TP.HCM siết nhà cao tầng các quận trung tâm   \n",
      "2  Sửng sốt với vẻ đẹp của ngôi nhà mê cung kết h...   \n",
      "3  3 tiêu chí vàng để làm đẹp bằng phương pháp că...   \n",
      "4  Tốt nghiệp thạc sĩ, chàng trai Quảng Ngãi quỳ ...   \n",
      "\n",
      "                                            document  \\\n",
      "0  Cơn bạo bệnh bất ngờ ập đếnCứ nhắc tới hai chữ...   \n",
      "1  Trong báo cáo gửi UBND TPHCM về đề án “Xây dựn...   \n",
      "2  Dự án cải tạo ngôi nhà kiêm thư viện, phòng kh...   \n",
      "3  Cùng lưu ý 3 tiêu chí vàng để căng chỉ tạo col...   \n",
      "4  Khoảnh khắc Hoàng Anh quỳ lạy công ơn của mẹ g...   \n",
      "\n",
      "                                             summary  \n",
      "0  Bài viết kể về hành trình chiến thắng ung thư ...  \n",
      "1  Sở Xây dựng TP.HCM đã báo cáo UBND về việc hạn...  \n",
      "2  Ngôi nhà Guha ở Indonesia là một dự án cải tạo...  \n",
      "3  Để thực hiện phương pháp căng chỉ tạo collagen...  \n",
      "4  Nguyễn Hoàng Anh, chàng trai từ Quảng Ngãi, đã...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "synthetic_title = []\n",
    "synthetic_document = []\n",
    "synthetic_summary = []\n",
    "\n",
    "# Lấy 100 mẫu đầu từ train\n",
    "samples = dataset[\"train\"].select(range(500))  # chọn 100 mẫu\n",
    "\n",
    "for sample in samples:\n",
    "    title = sample[\"title\"]\n",
    "    document = sample[\"document\"]\n",
    "    \n",
    "    # Gọi hàm tạo summary\n",
    "    new_summary = generate_synthetic_summary(title, document)\n",
    "\n",
    "    synthetic_title.append(title)\n",
    "    synthetic_document.append(document)\n",
    "    synthetic_summary.append(new_summary)\n",
    "\n",
    "# Tạo DataFrame\n",
    "synthetic_df = pd.DataFrame({\n",
    "    \"title\": synthetic_title,\n",
    "    \"document\": synthetic_document,\n",
    "    \"summary\": synthetic_summary\n",
    "})\n",
    "\n",
    "print(synthetic_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T11:55:51.716739Z",
     "iopub.status.busy": "2025-11-19T11:55:51.716521Z",
     "iopub.status.idle": "2025-11-19T11:55:51.762571Z",
     "shell.execute_reply": "2025-11-19T11:55:51.761881Z",
     "shell.execute_reply.started": "2025-11-19T11:55:51.716722Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic samples: 500\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "synthetic_dataset = Dataset.from_pandas(synthetic_df)\n",
    "\n",
    "print(\"Synthetic samples:\", len(synthetic_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T11:55:51.763589Z",
     "iopub.status.busy": "2025-11-19T11:55:51.763356Z",
     "iopub.status.idle": "2025-11-19T11:55:52.452836Z",
     "shell.execute_reply": "2025-11-19T11:55:52.452086Z",
     "shell.execute_reply.started": "2025-11-19T11:55:51.763573Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09283b5670724f4995691be6a3314dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_synthetic = synthetic_dataset.map(preprocess_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T11:55:52.454490Z",
     "iopub.status.busy": "2025-11-19T11:55:52.454280Z",
     "iopub.status.idle": "2025-11-19T11:55:52.463857Z",
     "shell.execute_reply": "2025-11-19T11:55:52.463053Z",
     "shell.execute_reply.started": "2025-11-19T11:55:52.454476Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train gốc: 2388\n",
      "Synthetic: 500\n",
      "Tổng train augmented: 2888\n"
     ]
    }
   ],
   "source": [
    "from datasets import concatenate_datasets\n",
    "\n",
    "aug_train_dataset = concatenate_datasets([\n",
    "    tokenized_dataset[\"train\"],\n",
    "    tokenized_synthetic\n",
    "])\n",
    "\n",
    "print(\"Train gốc:\", len(tokenized_dataset[\"train\"]))\n",
    "print(\"Synthetic:\", len(tokenized_synthetic))\n",
    "print(\"Tổng train augmented:\", len(aug_train_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T11:59:49.970804Z",
     "iopub.status.busy": "2025-11-19T11:59:49.970274Z",
     "iopub.status.idle": "2025-11-19T11:59:50.004522Z",
     "shell.execute_reply": "2025-11-19T11:59:50.003849Z",
     "shell.execute_reply.started": "2025-11-19T11:59:49.970781Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_args_2 = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./output_augmented\",\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-5,\n",
    "\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,                  \n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=50,               \n",
    "\n",
    "    save_strategy=\"no\",              \n",
    "    predict_with_generate=True,    \n",
    "    report_to=\"none\",                \n",
    "    fp16=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T11:59:51.781985Z",
     "iopub.status.busy": "2025-11-19T11:59:51.781706Z",
     "iopub.status.idle": "2025-11-19T11:59:52.059945Z",
     "shell.execute_reply": "2025-11-19T11:59:52.059169Z",
     "shell.execute_reply.started": "2025-11-19T11:59:51.781964Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48/561420147.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_2 = Seq2SeqTrainer(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainer_2 = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args_2,\n",
    "    train_dataset=aug_train_dataset,\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T11:59:56.172125Z",
     "iopub.status.busy": "2025-11-19T11:59:56.171339Z",
     "iopub.status.idle": "2025-11-19T12:35:50.772429Z",
     "shell.execute_reply": "2025-11-19T12:35:50.771770Z",
     "shell.execute_reply.started": "2025-11-19T11:59:56.172084Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='543' max='543' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [543/543 35:50, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.628400</td>\n",
       "      <td>1.678730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.508400</td>\n",
       "      <td>1.678709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.430600</td>\n",
       "      <td>1.669907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.343300</td>\n",
       "      <td>1.669558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.358200</td>\n",
       "      <td>1.670501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=543, training_loss=1.4552802407280516, metrics={'train_runtime': 2153.6437, 'train_samples_per_second': 4.023, 'train_steps_per_second': 0.252, 'total_flos': 1.02973827796992e+16, 'train_loss': 1.4552802407280516, 'epoch': 3.0})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_2.train()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T12:35:50.774044Z",
     "iopub.status.busy": "2025-11-19T12:35:50.773716Z",
     "iopub.status.idle": "2025-11-19T12:35:52.652550Z",
     "shell.execute_reply": "2025-11-19T12:35:52.651729Z",
     "shell.execute_reply.started": "2025-11-19T12:35:50.774024Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./model_summarization_augmented/tokenizer_config.json',\n",
       " './model_summarization_augmented/special_tokens_map.json',\n",
       " './model_summarization_augmented/spiece.model',\n",
       " './model_summarization_augmented/added_tokens.json',\n",
       " './model_summarization_augmented/tokenizer.json')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_2.save_model(\"./model_summarization_augmented\")\n",
    "tokenizer.save_pretrained(\"./model_summarization_augmented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T12:36:56.118915Z",
     "iopub.status.busy": "2025-11-19T12:36:56.118358Z",
     "iopub.status.idle": "2025-11-19T12:36:56.388768Z",
     "shell.execute_reply": "2025-11-19T12:36:56.388135Z",
     "shell.execute_reply.started": "2025-11-19T12:36:56.118890Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(36096, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(36096, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(36096, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=36096, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===== Load model 1 =====\n",
    "model1 = AutoModelForSeq2SeqLM.from_pretrained(\"./output_loss_only\")\n",
    "tokenizer1 = AutoTokenizer.from_pretrained(\"./output_loss_only\")\n",
    "\n",
    "model1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T12:37:02.540885Z",
     "iopub.status.busy": "2025-11-19T12:37:02.540109Z",
     "iopub.status.idle": "2025-11-19T12:37:02.814714Z",
     "shell.execute_reply": "2025-11-19T12:37:02.814026Z",
     "shell.execute_reply.started": "2025-11-19T12:37:02.540859Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(36096, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(36096, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(36096, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=36096, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===== Load model 2 =====\n",
    "model2 = AutoModelForSeq2SeqLM.from_pretrained(\"./model_summarization_augmented\")\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(\"./model_summarization_augmented\")\n",
    "\n",
    "model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T12:37:24.083558Z",
     "iopub.status.busy": "2025-11-19T12:37:24.082785Z",
     "iopub.status.idle": "2025-11-19T12:37:24.089178Z",
     "shell.execute_reply": "2025-11-19T12:37:24.088376Z",
     "shell.execute_reply.started": "2025-11-19T12:37:24.083532Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ===== Hàm summarize wrapper =====\n",
    "def summarize_model1(text, max_input_length=1024, max_output_length=200, min_output_length=80):\n",
    "    inputs = tokenizer1(text, return_tensors=\"pt\", truncation=True, max_length=max_input_length)\n",
    "    output_ids = model1.generate(\n",
    "        **inputs,\n",
    "        max_length=max_output_length,\n",
    "        min_length=min_output_length,\n",
    "        num_beams=5,\n",
    "        no_repeat_ngram_size=3,\n",
    "        length_penalty=1.0,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    return tokenizer1.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "def summarize_model2(text, max_input_length=1024, max_output_length=200, min_output_length=80):\n",
    "    inputs = tokenizer2(text, return_tensors=\"pt\", truncation=True, max_length=max_input_length)\n",
    "    output_ids = model2.generate(\n",
    "        **inputs,\n",
    "        max_length=max_output_length,\n",
    "        min_length=min_output_length,\n",
    "        num_beams=5,\n",
    "        no_repeat_ngram_size=3,\n",
    "        length_penalty=1.0,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    return tokenizer2.decode(output_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T12:37:24.742894Z",
     "iopub.status.busy": "2025-11-19T12:37:24.742305Z",
     "iopub.status.idle": "2025-11-19T12:37:24.746861Z",
     "shell.execute_reply": "2025-11-19T12:37:24.746119Z",
     "shell.execute_reply.started": "2025-11-19T12:37:24.742871Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ===== Test inference =====\n",
    "text = \"\"\"\n",
    "Chấm miếng ăn cắn dở vào bát nước chung không chỉ mất lịch sự, mà còn có thể lây truyền 10.000 vi khuẩn cho người khác, theo nghiên cứu của Đại học Clemson (Mỹ).\n",
    "Trong các bữa ăn, hành động chấm hai lần (double-dipping, nhúng miếng thức ăn đã cắn dở vào bát chấm chung) luôn là chủ đề gây tranh cãi. Nhiều người coi đây là thói quen mất vệ sinh, số khác lại cho rằng sự lo ngại này là thái quá.\n",
    "Nghiên cứu năm 2008 trên tạp chí An toàn thực phẩm (Journal of Food Safety) đã chứng minh hành vi này rất nguy hại. Nhóm nghiên cứu do tiến sĩ Paul Dawson, Đại học Clemson chủ trì đã dùng bánh quy chấm vào các loại sốt khác nhau, bao gồm nước vô trùng, sốt salsa, sốt phô mai và siro chocolate.\n",
    "Kết quả cho thấy vi khuẩn lây lan ở mức độ đáng báo động. Trung bình, chỉ 6 lần nhúng (miếng bánh đã cắn dở) đã chuyển khoảng 10.000 vi khuẩn từ miệng người ăn vào nước chấm.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T12:40:10.130852Z",
     "iopub.status.busy": "2025-11-19T12:40:10.130129Z",
     "iopub.status.idle": "2025-11-19T12:40:17.208050Z",
     "shell.execute_reply": "2025-11-19T12:40:17.207181Z",
     "shell.execute_reply.started": "2025-11-19T12:40:10.130826Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model1 summary: Theo nghiên cứu của Đại học Clemson (Mỹ), chấm miếng ăn đã cắn dở vào bát nước chung không chỉ mất lịch sự, mà còn có thể lây truyền 10.000 vi khuẩn từ miệng người ăn vào nước chấm, theo nghiên cứu năm 2008 trên tạp chí An toàn thực phẩm (Food Safety), gây nguy hiểm cho người khác.\n"
     ]
    }
   ],
   "source": [
    "print(\"Model1 summary:\", summarize_model1(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T12:40:17.209657Z",
     "iopub.status.busy": "2025-11-19T12:40:17.209382Z",
     "iopub.status.idle": "2025-11-19T12:40:27.488695Z",
     "shell.execute_reply": "2025-11-19T12:40:27.487958Z",
     "shell.execute_reply.started": "2025-11-19T12:40:17.209633Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model2 summary: Hành động chấm miếng ăn đã cắn dở vào bát nước chung không chỉ mất lịch sự, mà còn có thể lây truyền 10.000 vi khuẩn cho người khác, theo nghiên cứu của Đại học Clemson (Mỹ). Hành động này có thể gây nguy hiểm cho người ăn, theo một nghiên cứu năm 2008 trên tạp chí An toàn thực phẩm (Journal of Food Safety).\n"
     ]
    }
   ],
   "source": [
    "print(\"Model2 summary:\", summarize_model2(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T12:44:54.766345Z",
     "iopub.status.busy": "2025-11-19T12:44:54.765826Z",
     "iopub.status.idle": "2025-11-19T12:44:54.774182Z",
     "shell.execute_reply": "2025-11-19T12:44:54.773569Z",
     "shell.execute_reply.started": "2025-11-19T12:44:54.766312Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Giả sử test_dataset là Dataset của HF, đã có 'document' và 'summary'\n",
    "test_dataset = dataset['test']  # thêm dòng này trước khi dùng\n",
    "\n",
    "num_samples = 50\n",
    "docs = test_dataset[\"document\"][:num_samples]\n",
    "refs = test_dataset[\"summary\"][:num_samples]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T12:45:24.953461Z",
     "iopub.status.busy": "2025-11-19T12:45:24.952696Z",
     "iopub.status.idle": "2025-11-19T12:58:49.349665Z",
     "shell.execute_reply": "2025-11-19T12:58:49.348894Z",
     "shell.execute_reply.started": "2025-11-19T12:45:24.953419Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ===== Dự đoán với Model 1 =====\n",
    "pred_summaries_model1 = []\n",
    "for doc in docs:\n",
    "    summary = summarize_model1(doc, max_input_length=1024, max_output_length=256, min_output_length=120)\n",
    "    pred_summaries_model1.append(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T12:58:49.351666Z",
     "iopub.status.busy": "2025-11-19T12:58:49.351339Z",
     "iopub.status.idle": "2025-11-19T13:12:50.875758Z",
     "shell.execute_reply": "2025-11-19T13:12:50.875074Z",
     "shell.execute_reply.started": "2025-11-19T12:58:49.351641Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ===== Dự đoán với Model 2 =====\n",
    "pred_summaries_model2 = []\n",
    "for doc in docs:\n",
    "    summary = summarize_model2(doc, max_input_length=1024, max_output_length=256, min_output_length=120)\n",
    "    pred_summaries_model2.append(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T13:12:50.876921Z",
     "iopub.status.busy": "2025-11-19T13:12:50.876662Z",
     "iopub.status.idle": "2025-11-19T13:12:50.881518Z",
     "shell.execute_reply": "2025-11-19T13:12:50.880709Z",
     "shell.execute_reply.started": "2025-11-19T13:12:50.876898Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ===== Tạo DataFrame chuẩn bị đánh giá =====\n",
    "df_model1 = pd.DataFrame({\n",
    "    \"document\": docs,\n",
    "    \"reference_summary\": refs,\n",
    "    \"pred_summary_model1\": pred_summaries_model1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T13:12:50.882875Z",
     "iopub.status.busy": "2025-11-19T13:12:50.882688Z",
     "iopub.status.idle": "2025-11-19T13:12:50.899068Z",
     "shell.execute_reply": "2025-11-19T13:12:50.898432Z",
     "shell.execute_reply.started": "2025-11-19T13:12:50.882862Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_model2 = pd.DataFrame({\n",
    "    \"document\": docs,\n",
    "    \"reference_summary\": refs,\n",
    "    \"pred_summary_model2\": pred_summaries_model2\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T13:12:50.899972Z",
     "iopub.status.busy": "2025-11-19T13:12:50.899746Z",
     "iopub.status.idle": "2025-11-19T13:12:50.917688Z",
     "shell.execute_reply": "2025-11-19T13:12:50.917000Z",
     "shell.execute_reply.started": "2025-11-19T13:12:50.899947Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            document  \\\n",
      "0  Các VĐV tranh tài ở 48 bộ huy chương, gồm 26 b...   \n",
      "1  Bệnh viện K cho biết, ung thư thận ở giai đoạn...   \n",
      "2  Lương cao kèm điều kiện \"đánh đố\"Người lao độn...   \n",
      "\n",
      "                                   reference_summary  \\\n",
      "0  Hơn 350 vận động viên (VĐV) tham dự giải vô đị...   \n",
      "1  Tiểu ra máu có thể cảnh báo nhiều bệnh lý, tro...   \n",
      "2  Các doanh nghiệp ở TPHCM có nhu cầu tuyển gần ...   \n",
      "\n",
      "                                 pred_summary_model1  \n",
      "0  Trong khuôn khổ giải vô địch Vovinam châu Á 20...  \n",
      "1  Theo các chuyên gia, ung thư thận ở giai đoạn ...  \n",
      "2  Theo thống kê trực tuyến của Trung tâm Dịch vụ...  \n",
      "                                            document  \\\n",
      "0  Các VĐV tranh tài ở 48 bộ huy chương, gồm 26 b...   \n",
      "1  Bệnh viện K cho biết, ung thư thận ở giai đoạn...   \n",
      "2  Lương cao kèm điều kiện \"đánh đố\"Người lao độn...   \n",
      "\n",
      "                                   reference_summary  \\\n",
      "0  Hơn 350 vận động viên (VĐV) tham dự giải vô đị...   \n",
      "1  Tiểu ra máu có thể cảnh báo nhiều bệnh lý, tro...   \n",
      "2  Các doanh nghiệp ở TPHCM có nhu cầu tuyển gần ...   \n",
      "\n",
      "                                 pred_summary_model2  \n",
      "0  Giải Vovinam châu Á năm nay có sự tranh tài củ...  \n",
      "1  Bệnh viện K (Hà Nội) cho biết, ung thư thận ở ...  \n",
      "2  Theo quy định tại Nghị định 70, từ ngày 1/1/20...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# In thử 3 dòng đầu\n",
    "print(df_model1.head(3))\n",
    "print(df_model2.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T13:20:08.272707Z",
     "iopub.status.busy": "2025-11-19T13:20:08.271860Z",
     "iopub.status.idle": "2025-11-19T13:20:09.451221Z",
     "shell.execute_reply": "2025-11-19T13:20:09.450645Z",
     "shell.execute_reply.started": "2025-11-19T13:20:08.272672Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfe420734c424decb669c1ece6c2930e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "bertscore = evaluate.load(\"bertscore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T13:23:07.967404Z",
     "iopub.status.busy": "2025-11-19T13:23:07.966860Z",
     "iopub.status.idle": "2025-11-19T13:23:09.135216Z",
     "shell.execute_reply": "2025-11-19T13:23:09.134655Z",
     "shell.execute_reply.started": "2025-11-19T13:23:07.967381Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05b64d58963c4cc39067af5b635a0df3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rouge = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T13:24:26.259936Z",
     "iopub.status.busy": "2025-11-19T13:24:26.259270Z",
     "iopub.status.idle": "2025-11-19T13:24:28.266549Z",
     "shell.execute_reply": "2025-11-19T13:24:28.265726Z",
     "shell.execute_reply.started": "2025-11-19T13:24:26.259911Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ===== Số lượng sample test =====\n",
    "num_samples = 50\n",
    "refs = test_dataset[\"summary\"][:num_samples]\n",
    "\n",
    "# ===== ROUGE =====\n",
    "rouge_model1 = rouge.compute(predictions=pred_summaries_model1, references=refs)\n",
    "rouge_model2 = rouge.compute(predictions=pred_summaries_model2, references=refs)\n",
    "\n",
    "# Trung bình ROUGE F1\n",
    "avg_rouge_model1 = {k: v for k, v in rouge_model1.items()}\n",
    "avg_rouge_model2 = {k: v for k, v in rouge_model2.items()}\n",
    "\n",
    "# ===== BERTScore =====\n",
    "bertscore_model1 = bertscore.compute(predictions=pred_summaries_model1, references=refs, lang=\"vi\")\n",
    "bertscore_model2 = bertscore.compute(predictions=pred_summaries_model2, references=refs, lang=\"vi\")\n",
    "\n",
    "# Trung bình BERTScore: chuyển tất cả về float\n",
    "avg_bertscore_model1 = {k: float(sum(v))/len(v) for k, v in bertscore_model1.items() if k in [\"precision\",\"recall\",\"f1\"]}\n",
    "avg_bertscore_model2 = {k: float(sum(v))/len(v) for k, v in bertscore_model2.items() if k in [\"precision\",\"recall\",\"f1\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T13:24:28.656921Z",
     "iopub.status.busy": "2025-11-19T13:24:28.656216Z",
     "iopub.status.idle": "2025-11-19T13:24:28.664974Z",
     "shell.execute_reply": "2025-11-19T13:24:28.664135Z",
     "shell.execute_reply.started": "2025-11-19T13:24:28.656896Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Metric   Model 1   Model 2\n",
      "0              ROUGE-1  0.441434  0.429823\n",
      "1              ROUGE-2  0.213093  0.202547\n",
      "2              ROUGE-L  0.277753  0.273233\n",
      "3  BERTScore Precision  0.685912  0.682779\n",
      "4     BERTScore Recall  0.749460  0.754380\n",
      "5         BERTScore F1  0.716103  0.716505\n"
     ]
    }
   ],
   "source": [
    "# ===== Tạo bảng so sánh =====\n",
    "df_compare = pd.DataFrame({\n",
    "    \"Metric\": [\"ROUGE-1\", \"ROUGE-2\", \"ROUGE-L\", \"BERTScore Precision\", \"BERTScore Recall\", \"BERTScore F1\"],\n",
    "    \"Model 1\": [\n",
    "        avg_rouge_model1.get(\"rouge1\", 0),\n",
    "        avg_rouge_model1.get(\"rouge2\", 0),\n",
    "        avg_rouge_model1.get(\"rougeL\", 0),\n",
    "        avg_bertscore_model1[\"precision\"],\n",
    "        avg_bertscore_model1[\"recall\"],\n",
    "        avg_bertscore_model1[\"f1\"]\n",
    "    ],\n",
    "    \"Model 2\": [\n",
    "        avg_rouge_model2.get(\"rouge1\", 0),\n",
    "        avg_rouge_model2.get(\"rouge2\", 0),\n",
    "        avg_rouge_model2.get(\"rougeL\", 0),\n",
    "        avg_bertscore_model2[\"precision\"],\n",
    "        avg_bertscore_model2[\"recall\"],\n",
    "        avg_bertscore_model2[\"f1\"]\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(df_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T13:28:06.172029Z",
     "iopub.status.busy": "2025-11-19T13:28:06.171321Z",
     "iopub.status.idle": "2025-11-19T13:28:06.175528Z",
     "shell.execute_reply": "2025-11-19T13:28:06.174786Z",
     "shell.execute_reply.started": "2025-11-19T13:28:06.172006Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T13:28:08.071608Z",
     "iopub.status.busy": "2025-11-19T13:28:08.071061Z",
     "iopub.status.idle": "2025-11-19T13:28:08.077220Z",
     "shell.execute_reply": "2025-11-19T13:28:08.076546Z",
     "shell.execute_reply.started": "2025-11-19T13:28:08.071584Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_summarization_gpt4o_vi(document, reference, prediction):\n",
    "    system_prompt = \"\"\"\n",
    "Bạn là chuyên gia đánh giá tóm tắt văn bản.\n",
    "Đánh giá 4 tiêu chí (1–10):\n",
    "1️⃣ Fluency: Lưu loát & mạch lạc.\n",
    "2️⃣ Relevance: Liên quan & hữu ích.\n",
    "3️⃣ Faithfulness: Độ trung thực với nội dung gốc.\n",
    "4️⃣ Conciseness: Ngắn gọn, súc tích.\n",
    "\n",
    "Phải phản hồi **JSON hợp lệ**:\n",
    "{\n",
    "  \"fluency\": <điểm>,\n",
    "  \"relevance\": <điểm>,\n",
    "  \"faithfulness\": <điểm>,\n",
    "  \"conciseness\": <điểm>,\n",
    "  \"average\": <điểm>\n",
    "}\n",
    "\"\"\"\n",
    "    evaluation_prompt = f\"\"\"\n",
    "Văn bản gốc:\n",
    "{document}\n",
    "\n",
    "Tóm tắt chuẩn (reference):\n",
    "{reference}\n",
    "\n",
    "Tóm tắt mô hình (prediction):\n",
    "{prediction}\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": evaluation_prompt}\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        # Lấy JSON từ GPT\n",
    "        raw_text = response.choices[0].message.content.strip()\n",
    "        result = json.loads(raw_text)\n",
    "        # Ép kiểu float\n",
    "        for k in result:\n",
    "            result[k] = float(result[k])\n",
    "    except Exception as e:\n",
    "        print(\"⚠️ Lỗi API hoặc lỗi JSON:\", e)\n",
    "        result = {k: None for k in [\"fluency\",\"relevance\",\"faithfulness\",\"conciseness\",\"average\"]}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T13:28:10.156847Z",
     "iopub.status.busy": "2025-11-19T13:28:10.156137Z",
     "iopub.status.idle": "2025-11-19T13:28:10.163890Z",
     "shell.execute_reply": "2025-11-19T13:28:10.163275Z",
     "shell.execute_reply.started": "2025-11-19T13:28:10.156821Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_samples = 50\n",
    "docs = test_dataset[\"document\"][:num_samples]\n",
    "refs = test_dataset[\"summary\"][:num_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T13:28:18.679125Z",
     "iopub.status.busy": "2025-11-19T13:28:18.678840Z",
     "iopub.status.idle": "2025-11-19T13:29:30.372851Z",
     "shell.execute_reply": "2025-11-19T13:29:30.372138Z",
     "shell.execute_reply.started": "2025-11-19T13:28:18.679092Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Evaluating Model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:11<00:00,  1.43s/it]\n"
     ]
    }
   ],
   "source": [
    "evals_model1 = []\n",
    "evals_model2 = []\n",
    "\n",
    "print(\"🔹 Evaluating Model 1\")\n",
    "for i in tqdm(range(num_samples)):\n",
    "    eval_result = evaluate_summarization_gpt4o_vi(\n",
    "        document=docs[i],\n",
    "        reference=refs[i],\n",
    "        prediction=pred_summaries_model1[i]\n",
    "    )\n",
    "    evals_model1.append(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T13:29:30.374443Z",
     "iopub.status.busy": "2025-11-19T13:29:30.374203Z",
     "iopub.status.idle": "2025-11-19T13:30:37.368165Z",
     "shell.execute_reply": "2025-11-19T13:30:37.367475Z",
     "shell.execute_reply.started": "2025-11-19T13:29:30.374426Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model 2: 100%|██████████| 50/50 [01:06<00:00,  1.34s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(num_samples), desc=\"Evaluating Model 2\"):\n",
    "    eval_result = evaluate_summarization_gpt4o_vi(\n",
    "        document=docs[i],\n",
    "        reference=refs[i],\n",
    "        prediction=pred_summaries_model2[i]\n",
    "    )\n",
    "    evals_model2.append(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T13:31:02.072465Z",
     "iopub.status.busy": "2025-11-19T13:31:02.071874Z",
     "iopub.status.idle": "2025-11-19T13:31:02.076968Z",
     "shell.execute_reply": "2025-11-19T13:31:02.076207Z",
     "shell.execute_reply.started": "2025-11-19T13:31:02.072439Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Chuyển sang DataFrame\n",
    "df_gpt_eval = pd.DataFrame({\n",
    "    \"document\": docs,\n",
    "    \"reference_summary\": refs,\n",
    "    \"pred_model1\": pred_summaries_model1,\n",
    "    \"pred_model2\": pred_summaries_model2,\n",
    "    \"eval_model1\": evals_model1,\n",
    "    \"eval_model2\": evals_model2\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T13:31:03.904628Z",
     "iopub.status.busy": "2025-11-19T13:31:03.904078Z",
     "iopub.status.idle": "2025-11-19T13:31:03.911899Z",
     "shell.execute_reply": "2025-11-19T13:31:03.911156Z",
     "shell.execute_reply.started": "2025-11-19T13:31:03.904604Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Tách riêng các cột điểm cho dễ tính trung bình\n",
    "for criterion in [\"fluency\",\"relevance\",\"faithfulness\",\"conciseness\",\"average\"]:\n",
    "    df_gpt_eval[f\"{criterion}_model1\"] = [e[criterion] for e in evals_model1]\n",
    "    df_gpt_eval[f\"{criterion}_model2\"] = [e[criterion] for e in evals_model2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T13:31:04.240609Z",
     "iopub.status.busy": "2025-11-19T13:31:04.240307Z",
     "iopub.status.idle": "2025-11-19T13:31:04.247621Z",
     "shell.execute_reply": "2025-11-19T13:31:04.246807Z",
     "shell.execute_reply.started": "2025-11-19T13:31:04.240582Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Tính điểm trung bình tổng thể cho 2 model\n",
    "avg_scores_model1 = df_gpt_eval[[f\"{c}_model1\" for c in [\"fluency\",\"relevance\",\"faithfulness\",\"conciseness\",\"average\"]]].mean()\n",
    "avg_scores_model2 = df_gpt_eval[[f\"{c}_model2\" for c in [\"fluency\",\"relevance\",\"faithfulness\",\"conciseness\",\"average\"]]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T13:31:05.954345Z",
     "iopub.status.busy": "2025-11-19T13:31:05.953964Z",
     "iopub.status.idle": "2025-11-19T13:31:05.961855Z",
     "shell.execute_reply": "2025-11-19T13:31:05.960996Z",
     "shell.execute_reply.started": "2025-11-19T13:31:05.954294Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Metric  Model 1  Model 2\n",
      "0       Fluency     6.44     7.42\n",
      "1     Relevance     7.18     8.12\n",
      "2  Faithfulness     5.66     6.84\n",
      "3   Conciseness     4.92     6.10\n",
      "4       Average     6.05     7.12\n"
     ]
    }
   ],
   "source": [
    "df_avg_gpt = pd.DataFrame({\n",
    "    \"Metric\": [\"Fluency\",\"Relevance\",\"Faithfulness\",\"Conciseness\",\"Average\"],\n",
    "    \"Model 1\": avg_scores_model1.values,\n",
    "    \"Model 2\": avg_scores_model2.values\n",
    "})\n",
    "\n",
    "print(df_avg_gpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T13:34:17.908725Z",
     "iopub.status.busy": "2025-11-19T13:34:17.908448Z",
     "iopub.status.idle": "2025-11-19T13:34:17.929062Z",
     "shell.execute_reply": "2025-11-19T13:34:17.928267Z",
     "shell.execute_reply.started": "2025-11-19T13:34:17.908704Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d95662f232d1414794fe6557183fc1d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ✅ 1. Đăng nhập Hugging Face\n",
    "from huggingface_hub import login\n",
    "login(new_session=False)  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T13:34:31.882507Z",
     "iopub.status.busy": "2025-11-19T13:34:31.881966Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df4557cd9942429a99da13838101d004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e19cf8de978046fb8ecc8353ef4e9b8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.push_to_hub(\"letri/vit5_text summarization\")\n",
    "trainer.push_to_hub(\"letri/vit5_text summarization_Synthetic Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
